{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CCF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYHgrBp-5QJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install nltk and download language packages\n",
        "!python3 -m nltk.downloader wordnet punkt averaged_perceptron_tagger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkzgqai-5YdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from util import load_json, dump_json\n",
        "\n",
        "seed = 17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb8kir6m9ljs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de2fda31-4cb2-4a5b-c0f8-825604c51bb3"
      },
      "source": [
        "# text processing and cleanup\n",
        "!python3 preprocess_data.py -a output.txt -o data.json"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9991it [01:14, 133.64it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um08talo5fCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put data into a pandas\n",
        "articles = load_json('data.json')\n",
        "article_properties = list(sorted(articles[0].keys()))\n",
        "articles_dict = {article_property: [article[article_property] for article in articles] for article_property in article_properties}\n",
        "articles_df = pd.DataFrame.from_dict(articles_dict)\n",
        "articles_train_df, articles_test_df = train_test_split(articles_df, test_size=0.001, random_state=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdq7VOM7qwG",
        "colab_type": "code",
        "outputId": "44e9a241-f11b-49dd-e6fa-1dcb3a9b18d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "articles_df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>fos</th>\n",
              "      <th>id</th>\n",
              "      <th>references</th>\n",
              "      <th>title</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vehicle communication channel characteristic e...</td>\n",
              "      <td>[computer science, bit error rate, computer ne...</td>\n",
              "      <td>1000096266</td>\n",
              "      <td>[1801089468, 1963850605, 2064076416, 211953192...</td>\n",
              "      <td>Pilots Aided Channel Estimation for Doubly Sel...</td>\n",
              "      <td>2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>develop coupled thermomechanical model include...</td>\n",
              "      <td>[mathematical optimization, mathematics, conti...</td>\n",
              "      <td>1000117647</td>\n",
              "      <td>[2115718968, 2151110682]</td>\n",
              "      <td>Mould-taper asymptotics and air gap formation ...</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>increase popularity social network globalize e...</td>\n",
              "      <td>[data security, secrecy, database, encryption,...</td>\n",
              "      <td>100013375</td>\n",
              "      <td>[132109442, 1768601545, 2100727725, 2119028650...</td>\n",
              "      <td>Data Protection and Privacy Preservation Using...</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>research design privacy preserve schedule serv...</td>\n",
              "      <td>[real time compute, computer network, computer...</td>\n",
              "      <td>100013628</td>\n",
              "      <td>[1979788481, 1995801303, 2016721869, 211567220...</td>\n",
              "      <td>Privacy-preserving scheduling mechanism for eh...</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>design privacy aware system gain attention rec...</td>\n",
              "      <td>[system engineering, data mining, privacy desi...</td>\n",
              "      <td>100014528</td>\n",
              "      <td>[34239548, 140430729, 1510827835, 1918077612, ...</td>\n",
              "      <td>Applying Soft Computing Technologies for Imple...</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            abstract  ...  year\n",
              "0  vehicle communication channel characteristic e...  ...  2013\n",
              "1  develop coupled thermomechanical model include...  ...  2015\n",
              "2  increase popularity social network globalize e...  ...  2012\n",
              "3  research design privacy preserve schedule serv...  ...  2012\n",
              "4  design privacy aware system gain attention rec...  ...  2012\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b35MxCI6C6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count occurrences of words in training data\n",
        "count_vectorizer = CountVectorizer()\n",
        "corpus = [article['abstract'] for _, article in articles_train_df.iterrows()]\n",
        "count_vectorizer.fit(corpus)\n",
        "\n",
        "# create a dataframe of counts slowly to not fill up the memory\n",
        "step_size = 1000\n",
        "count_cols = ['vocab_{}'.format(word) for word in count_vectorizer.get_feature_names()]\n",
        "counts_df = pd.DataFrame(columns=count_cols)\n",
        "for i in range(0, len(articles_train_df), step_size):\n",
        "  corpus = [article['abstract'] for _, article in articles_train_df.iloc[[k for k in range(i, min(i+step_size+1, len(articles_train_df)))]].iterrows()]\n",
        "  counts = count_vectorizer.transform(corpus)\n",
        "  step_counts_df = pd.DataFrame(counts.todense(), columns=count_cols)\n",
        "  counts_df = pd.concat([counts_df, step_counts_df], ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOypeDUnQ3cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the counts dataframe to training dataframe\n",
        "train_counts_df = pd.concat([articles_train_df, counts_df], axis=1)\n",
        "train_counts_no_nans_df = train_counts_df[count_cols].fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrm6IGOVTBqW",
        "colab_type": "code",
        "outputId": "b950f923-b3e5-492d-86f7-3eed1d409e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check for nulls\n",
        "train_counts_no_nans_df[count_cols].isnull().sum().sum()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AowKxMg1FIy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed09e95b-dae0-4525-9f66-f7920736d854"
      },
      "source": [
        "# vocabulary size\n",
        "len(count_vectorizer.get_feature_names())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hnoiw3GcbnSC",
        "colab": {}
      },
      "source": [
        "# function that will keep score for a given k for top k candidates\n",
        "def get_test_score(model, train_df, test_df, scores, top_k=200):\n",
        "  # check if top_k vectors with highest cosine similarity have one of the cited papers\n",
        "  score = 0\n",
        "  num_examples = len(test_df)\n",
        "  score_indices = np.argsort(scores, axis=1)\n",
        "  for i, (_, row) in enumerate(test_df.iterrows()):\n",
        "    citations = row['references']\n",
        "    if type(citations) == list:\n",
        "      top_k_docs = score_indices[i][::-1][:top_k]\n",
        "      top_k_docs_ids = train_df.iloc[top_k_docs]['id'].tolist()\n",
        "      if any(citation in top_k_docs_ids for citation in citations):\n",
        "        score += 1\n",
        "      elif not any(train_df['id'].isin(citations)):\n",
        "        num_examples -= 1\n",
        "    else:\n",
        "      num_examples -= 1\n",
        "    \n",
        "    print(i, num_examples, score, score / num_examples)\n",
        "\n",
        "  return score / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3K-Phn16tQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CV grid search for best n_components\n",
        "n_splits = 2\n",
        "kf = KFold(n_splits=n_splits, random_state=seed)\n",
        "scores = []\n",
        "base_n_components = 12\n",
        "for n in range(base_n_components, 15):\n",
        "  fold_scores = []\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(train_counts_no_nans_df)):\n",
        "    train_df = train_counts_no_nans_df.iloc[train_index]\n",
        "    validate_df = train_counts_no_nans_df.iloc[test_index]\n",
        "    lda = LatentDirichletAllocation(n_components=n, random_state=seed)\n",
        "    lda.fit(train_df[count_cols])\n",
        "    X = lda.transform(train_counts_no_nans_df[count_cols])\n",
        "    X_validate = lda.transform(validate_df[count_cols])\n",
        "    score = get_test_score(lda, train_counts_df, train_counts_df.iloc[test_index], np.matmul(X_validate, X.T))\n",
        "    fold_scores += [score]\n",
        "    print(n, score)\n",
        "  scores += [sum(fold_scores) / len(fold_scores)]\n",
        "\n",
        "# found the best n\n",
        "best_n_components = base_n_components + scores.index(max(scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyerBcSZ7W3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate lda\n",
        "best_lda = LatentDirichletAllocation(n_components=best_n_components, random_state=seed)\n",
        "best_lda.fit(train_counts_df[count_cols])\n",
        "X_train = best_lda.fit_transform(train_counts_df[count_cols])\n",
        "X_test = best_lda.transform(test_counts_df[count_cols])\n",
        "print('Top 5:', get_test_score(best_lda, train_counts_df, X_train, test_counts_df, X_test, top_k=5))\n",
        "print('Top 10:', get_test_score(best_lda, train_counts_df, X_train, test_counts_df, X_test, top_k=10))\n",
        "print('Top 20:', get_test_score(best_lda, train_counts_df, X_train, test_counts_df, X_test, top_k=20))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}