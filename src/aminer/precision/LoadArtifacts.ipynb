{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import EnglishTextProcessor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etp = EnglishTextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pickle.load(open('vec.model', 'rb'))\n",
    "fasttext = FastText.load('fasttext.model')\n",
    "\n",
    "word_to_idx = list(vec.get_feature_names())\n",
    "\n",
    "idx_to_word = {}\n",
    "for i, word in enumerate(word_to_idx):\n",
    "    idx_to_word[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_folder = 'abstract_dictionaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_id_and_abstracts(abstract_folder):\n",
    "    json_file_names = sorted(os.listdir(abstract_folder), key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    for file_name in json_file_names:\n",
    "        file_path = os.path.join(abstract_folder, file_name)\n",
    "        try:\n",
    "            id_to_abstract_dict = None\n",
    "            with open(file_path) as id_to_abstract_json_file:\n",
    "                id_to_abstract_dict = json.load(id_to_abstract_json_file)\n",
    "\n",
    "            for id in id_to_abstract_dict:\n",
    "                yield id, id_to_abstract_dict[id]\n",
    "\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(abstract_folder):\n",
    "    json_file_names = sorted(os.listdir(abstract_folder), key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    for file_name in json_file_names:\n",
    "        file_path = os.path.join(abstract_folder, file_name)\n",
    "        try:\n",
    "            id_to_abstract_dict = None\n",
    "            with open(file_path) as id_to_abstract_json_file:\n",
    "                id_to_abstract_dict = json.load(id_to_abstract_json_file)\n",
    "\n",
    "            yield id_to_abstract_dict\n",
    "\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def compute_abstract_embedding(abstract):\n",
    "    tfidf_vec = vec.transform([abstract])\n",
    "    tfidf_vec = scipy.sparse.coo_matrix(tfidf_vec)\n",
    "    word_count = 0\n",
    "    sum_embedding = np.zeros(50)\n",
    "    for _, word_index, word_tfidf in zip(tfidf_vec.row, tfidf_vec.col, tfidf_vec.data):\n",
    "        word = word_to_idx[word_index]\n",
    "        if word in fasttext.wv.vocab:\n",
    "            word_count += 1\n",
    "            sum_embedding += fasttext.wv[word]\n",
    "    \n",
    "    if word_count == 0:\n",
    "        return [0]*50\n",
    "    \n",
    "    return (sum_embedding / word_count).tolist()\n",
    "\n",
    "def dump_json(d, output_file_path):\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        json.dump(d, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_to_embedding = None\n",
    "for i, batch in enumerate(iter_batches(abstract_folder)):\n",
    "    id_to_embedding = {}\n",
    "    for id in batch:\n",
    "        processed_abstract = etp(batch[id])\n",
    "        embedding = compute_abstract_embedding(processed_abstract)\n",
    "        id_to_embedding[id] = embedding\n",
    "\n",
    "    dump_json(id_to_embedding, 'id_to_embedding_dict_{}.json'.format(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccf",
   "language": "python",
   "name": "ccf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
